{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m82c7h1ny3Ae",
    "outputId": "ed642daa-e8d7-4fd8-a694-4c7055fc7768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: numpy in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (1.21.6)\n",
      "Requirement already satisfied: scikit-learn in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (1.2.2)\n",
      "Requirement already satisfied: torch in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: networkx in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: filelock in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: sympy in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/sahilarora/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JjflVO2Jy4KE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
    "column_names = ['checking_account', 'duration', 'credit_history', 'purpose', 'credit_amount',\n",
    "                'savings_account', 'employment', 'installment_rate', 'personal_status_sex',\n",
    "                'debtors_guarantors', 'residence', 'property', 'age', 'other_installment_plans',\n",
    "                'housing', 'credits', 'job', 'liable_people', 'telephone', 'foreign_worker', 'credit_risk']\n",
    "data = pd.read_csv(url, names=column_names, delimiter=' ')\n",
    "\n",
    "# Preprocess the categorical variables using one-hot encoding\n",
    "data = pd.get_dummies(data, columns=['checking_account', 'credit_history', 'purpose', 'savings_account', 'employment',\n",
    "                                     'personal_status_sex', 'debtors_guarantors', 'property', 'other_installment_plans',\n",
    "                                     'housing', 'job', 'telephone', 'foreign_worker'])\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop(columns=['credit_risk'])\n",
    "y = data['credit_risk'].map({1: 0, 2: 1})  # Map the target variable to 0 (good risk) and 1 (bad risk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "D-JoMjiAy6M4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Standardize the continuous features\n",
    "# Standardize the continuous features\n",
    "continuous_features = ['duration', 'credit_amount', 'installment_rate', 'age', 'credits', 'liable_people']\n",
    "scaler = StandardScaler()\n",
    "X[continuous_features] = scaler.fit_transform(X[continuous_features])\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "# Convert the data into PyTorch tensors\n",
    "\n",
    "# Convert all columns to float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "# Convert the data into PyTorch tensors\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_val = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iu1ElnKEy8pm",
    "outputId": "5a808707-8cd2-4178-de2a-b89cb46590d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.5950955748558044, Validation Loss: 0.6103551983833313\n",
      "Epoch 2/50, Loss: 0.561471700668335, Validation Loss: 0.5869834423065186\n",
      "Epoch 3/50, Loss: 0.5629627108573914, Validation Loss: 0.5701571702957153\n",
      "Epoch 4/50, Loss: 0.5227663516998291, Validation Loss: 0.5375768542289734\n",
      "Epoch 5/50, Loss: 0.5099400281906128, Validation Loss: 0.5100570321083069\n",
      "Epoch 6/50, Loss: 0.461517870426178, Validation Loss: 0.5108264684677124\n",
      "Epoch 7/50, Loss: 0.4795411229133606, Validation Loss: 0.48736611008644104\n",
      "Epoch 8/50, Loss: 0.4156927466392517, Validation Loss: 0.5020230412483215\n",
      "Epoch 9/50, Loss: 0.3824921250343323, Validation Loss: 0.5134875774383545\n",
      "Epoch 10/50, Loss: 0.4427129328250885, Validation Loss: 0.5200778841972351\n",
      "Epoch 11/50, Loss: 0.4253544807434082, Validation Loss: 0.5406981706619263\n",
      "Epoch 12/50, Loss: 0.36217278242111206, Validation Loss: 0.5232943296432495\n",
      "Epoch 13/50, Loss: 0.3856695592403412, Validation Loss: 0.5294525027275085\n",
      "Epoch 14/50, Loss: 0.32544153928756714, Validation Loss: 0.515060305595398\n",
      "Epoch 15/50, Loss: 0.35010525584220886, Validation Loss: 0.5427337288856506\n",
      "Epoch 16/50, Loss: 0.33635520935058594, Validation Loss: 0.5380688905715942\n",
      "Epoch 17/50, Loss: 0.3077017068862915, Validation Loss: 0.5287113785743713\n",
      "Epoch 18/50, Loss: 0.26084625720977783, Validation Loss: 0.5261017680168152\n",
      "Epoch 19/50, Loss: 0.3048873245716095, Validation Loss: 0.5166292786598206\n",
      "Epoch 20/50, Loss: 0.29086002707481384, Validation Loss: 0.566437304019928\n",
      "Epoch 21/50, Loss: 0.38788944482803345, Validation Loss: 0.5424609780311584\n",
      "Epoch 22/50, Loss: 0.30730533599853516, Validation Loss: 0.5528055429458618\n",
      "Epoch 23/50, Loss: 0.26788532733917236, Validation Loss: 0.58296799659729\n",
      "Epoch 24/50, Loss: 0.19953365623950958, Validation Loss: 0.6117995977401733\n",
      "Epoch 25/50, Loss: 0.21140190958976746, Validation Loss: 0.6745118498802185\n",
      "Epoch 26/50, Loss: 0.2015920728445053, Validation Loss: 0.5884829163551331\n",
      "Epoch 27/50, Loss: 0.1739361584186554, Validation Loss: 0.6314935088157654\n",
      "Epoch 28/50, Loss: 0.1854751706123352, Validation Loss: 0.6705418229103088\n",
      "Epoch 29/50, Loss: 0.18980787694454193, Validation Loss: 0.5879566073417664\n",
      "Epoch 30/50, Loss: 0.15230563282966614, Validation Loss: 0.6623739004135132\n",
      "Epoch 31/50, Loss: 0.1988707035779953, Validation Loss: 0.6675594449043274\n",
      "Epoch 32/50, Loss: 0.19172286987304688, Validation Loss: 0.6943446397781372\n",
      "Epoch 33/50, Loss: 0.14284706115722656, Validation Loss: 0.7197985053062439\n",
      "Epoch 34/50, Loss: 0.1546327918767929, Validation Loss: 0.7606306076049805\n",
      "Epoch 35/50, Loss: 0.1163785308599472, Validation Loss: 0.7816420793533325\n",
      "Epoch 36/50, Loss: 0.16384735703468323, Validation Loss: 0.7703357338905334\n",
      "Epoch 37/50, Loss: 0.11598453670740128, Validation Loss: 0.8015376329421997\n",
      "Epoch 38/50, Loss: 0.2318095713853836, Validation Loss: 0.7826115489006042\n",
      "Epoch 39/50, Loss: 0.19721181690692902, Validation Loss: 0.8479219675064087\n",
      "Epoch 40/50, Loss: 0.16710083186626434, Validation Loss: 0.8839325904846191\n",
      "Epoch 41/50, Loss: 0.1908322423696518, Validation Loss: 0.8575023412704468\n",
      "Epoch 42/50, Loss: 0.11084368079900742, Validation Loss: 0.954947292804718\n",
      "Epoch 43/50, Loss: 0.10384078323841095, Validation Loss: 0.9643468856811523\n",
      "Epoch 44/50, Loss: 0.06401477754116058, Validation Loss: 0.8547893762588501\n",
      "Epoch 45/50, Loss: 0.1009642705321312, Validation Loss: 0.965157151222229\n",
      "Epoch 46/50, Loss: 0.07410275936126709, Validation Loss: 0.8746001124382019\n",
      "Epoch 47/50, Loss: 0.24934875965118408, Validation Loss: 0.9570902585983276\n",
      "Epoch 48/50, Loss: 0.07968895137310028, Validation Loss: 0.8771101832389832\n",
      "Epoch 49/50, Loss: 0.18089404702186584, Validation Loss: 0.8851597905158997\n",
      "Epoch 50/50, Loss: 0.07904496043920517, Validation Loss: 0.953055739402771\n"
     ]
    }
   ],
   "source": [
    "class CreditScoringModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CreditScoringModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = CreditScoringModel(X_train.shape[1])\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "n_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i + batch_size]\n",
    "        y_batch = y_train[i:i + batch_size]\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate the validation loss\n",
    "    y_val_pred = model(X_val)\n",
    "    val_loss = criterion(y_val_pred, y_val)\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEqxNhv_zEHa",
    "outputId": "0a30a1da-a3b2-4b82-de16-935b5280efa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.755\n",
      "Confusion Matrix:\n",
      " [[111  30]\n",
      " [ 19  40]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.79      0.82       141\n",
      "         1.0       0.57      0.68      0.62        59\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.71      0.73      0.72       200\n",
      "weighted avg       0.77      0.76      0.76       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model(X_test)\n",
    "y_pred = (y_pred.detach().numpy() > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WR6AjrVpzPzg"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"credit_risk_model_1.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"credit_risk_model_2.pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
